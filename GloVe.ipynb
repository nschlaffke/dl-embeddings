{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import Word2Vec\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "from glove import Glove, Corpus\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_COUNT = 5 # the minimal number of occurences for a particular word in order to be included\n",
    "SIZE = 300 # the size of the embedding\n",
    "TEST_SET = 0.2\n",
    "T_SNE = False\n",
    "K_MEANS = True\n",
    "CLASSIFIER = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = fetch_20newsgroups(subset='all', shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(line):\n",
    "    line = re.sub('[!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n]', ' ', line)\n",
    "    line = re.sub('[0-9]', '', line)\n",
    "    words = line.lower().split()\n",
    "    proper = []\n",
    "    for word in words:\n",
    "        if len(word) > 2:\n",
    "            proper.append(word)\n",
    "    return proper\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset.data, dataset.target, test_size=TEST_SET)\n",
    "X_train, X_test = [preproc(line) for line in X_train], [preproc(line) for line in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 30 training epochs with 8 threads\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n"
     ]
    }
   ],
   "source": [
    "corpus = Corpus()\n",
    "corpus.fit(X_train)\n",
    "\n",
    "glove = Glove(no_components=SIZE, learning_rate=0.05)\n",
    " \n",
    "glove.fit(corpus.matrix, epochs=30, no_threads=8, verbose=True)\n",
    "glove.add_dictionary(corpus.dictionary)\n",
    "model = glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.29680462e-01,  2.03904166e-01,  8.89107637e-02, -1.54881783e-01,\n",
       "        2.51916101e-01,  3.80483315e-02,  3.05416478e-01,  2.28546549e-02,\n",
       "       -1.26759974e-01,  2.28333708e-01,  4.84659946e-02, -1.84331748e-01,\n",
       "        1.24411462e-01, -7.67160179e-02,  9.31707164e-02, -1.99920467e-01,\n",
       "       -5.24743849e-02, -7.93961185e-02, -1.32804040e-01,  8.85677009e-02,\n",
       "       -2.86782349e-01, -1.42096356e-01, -2.61349180e-01, -1.43584834e-01,\n",
       "        9.32634025e-03,  1.34729896e-01,  1.20198947e-01,  2.34515197e-01,\n",
       "        1.21955635e-01,  1.36529456e-01,  1.58619176e-01,  8.48278654e-02,\n",
       "       -1.85386394e-01,  1.38982882e-01,  1.51485042e-01,  1.00034582e-01,\n",
       "       -4.31165617e-01, -1.72589170e-01,  1.66632175e-01, -1.15527113e-01,\n",
       "        1.96738025e-01,  8.24328357e-04, -2.12845243e-01, -4.61287390e-02,\n",
       "       -4.22331482e-02,  3.78180679e-02,  1.52784823e-01,  1.50386238e-02,\n",
       "       -3.06157699e-01,  4.03075611e-01, -2.40698052e-01, -1.74673204e-01,\n",
       "       -1.65147412e-01,  1.99996159e-01, -4.30309972e-03,  1.73585553e-01,\n",
       "        1.05167561e-01,  1.39949840e-01, -5.05746210e-02,  8.65202241e-03,\n",
       "        2.50547714e-01,  4.19014607e-02,  1.82268768e-01,  2.30621031e-01,\n",
       "        1.60317893e-01, -1.98690302e-01,  1.59960444e-01, -1.82880425e-02,\n",
       "        1.90835862e-01, -6.51499339e-02,  7.55155971e-02,  2.19643459e-01,\n",
       "        1.10899522e-02,  1.87243028e-01,  2.68603660e-01,  2.56277621e-01,\n",
       "        2.16723512e-01, -2.49989342e-01, -2.98666697e-02,  7.70948563e-02,\n",
       "        2.74226330e-01,  1.81905462e-01, -1.64315573e-01,  1.30859171e-01,\n",
       "       -1.96585818e-01,  3.29560494e-02,  1.71921135e-01, -1.25490446e-01,\n",
       "        2.15046552e-02, -2.59164439e-01, -2.54439371e-01,  4.00220344e-01,\n",
       "        3.91252447e-01,  1.12513754e-01,  3.18071309e-01,  1.73503751e-01,\n",
       "       -1.48845490e-01,  1.61567316e-01, -2.03636307e-01,  2.60685911e-02,\n",
       "        1.74412734e-01, -2.24835048e-01,  4.81683870e-01, -3.69463561e-04,\n",
       "       -1.78220446e-01,  3.12845770e-02,  1.37789823e-01,  1.74926773e-01,\n",
       "        1.60623057e-02,  5.16129489e-02,  1.22430548e-01, -2.23521243e-01,\n",
       "       -3.33726522e-01, -1.80122630e-01,  3.90488845e-02,  1.05783684e-02,\n",
       "       -3.40572092e-01, -2.84094495e-01,  2.36396885e-01,  1.66529518e-01,\n",
       "       -2.84022062e-02, -2.19651987e-01,  1.66970578e-01,  1.35944317e-01,\n",
       "        3.00662497e-01, -2.15627751e-01,  2.73461206e-01,  1.91295165e-03,\n",
       "        3.08653294e-01,  5.45144954e-02, -1.60152869e-02,  1.39500011e-01,\n",
       "        4.70057122e-02,  2.27117363e-02, -3.75958455e-02,  8.32358830e-02,\n",
       "       -1.21294766e-01, -6.67389502e-02, -1.56776992e-01, -1.31649396e-01,\n",
       "       -7.77376034e-02,  1.29830906e-01, -3.02534953e-02, -4.17636059e-02,\n",
       "       -1.99469248e-01, -1.40979953e-01, -1.30020538e-01,  1.34502755e-02,\n",
       "        2.07075427e-01,  1.97162614e-01, -2.64351302e-01, -4.07003219e-02,\n",
       "       -7.97710608e-03,  4.67500210e-02,  3.45700092e-01, -8.14558836e-02,\n",
       "       -1.36376768e-01, -4.63466588e-02, -7.35428189e-02,  1.83826284e-01,\n",
       "        3.16704103e-01,  2.15120470e-01, -2.91042546e-01, -4.08594923e-02,\n",
       "       -9.77925406e-02,  1.90461583e-01,  1.55271499e-02,  1.64595128e-01,\n",
       "        9.54722649e-02, -1.84175121e-01, -2.61720450e-01, -1.47471575e-01,\n",
       "       -1.25825797e-01, -1.57616906e-01,  1.61147724e-01,  1.81945925e-01,\n",
       "       -2.44456859e-01,  9.89373803e-02, -1.03902050e-01, -6.24721100e-02,\n",
       "        8.55428819e-02, -5.23695217e-01,  9.28941422e-02,  1.19405605e-01,\n",
       "       -2.69633120e-01, -2.60028617e-01, -2.69012991e-02, -2.88823264e-01,\n",
       "        3.24688458e-02, -3.51987467e-01,  1.66644638e-01,  9.01431190e-03,\n",
       "       -1.34662326e-01,  1.32942311e-02, -1.91195728e-01,  1.65006112e-01,\n",
       "        1.03344532e-01, -1.20846613e-01,  3.32309871e-01, -4.10984739e-02,\n",
       "       -8.34593342e-02,  4.01737115e-01, -1.25793069e-02, -1.32548193e-02,\n",
       "       -5.10254199e-02, -5.04074988e-01, -2.18148579e-01,  1.60993145e-01,\n",
       "       -1.12143960e-01, -1.07203165e-01, -2.25552064e-01,  3.25226345e-01,\n",
       "       -2.61307478e-01,  1.34725594e-01, -1.96426020e-01, -1.75918863e-01,\n",
       "       -1.87479989e-01, -3.27295485e-01, -1.25482843e-01,  1.66832829e-01,\n",
       "       -1.39850840e-02,  2.27321184e-01, -1.51795906e-01,  4.76371875e-02,\n",
       "       -2.65583703e-01, -1.54155847e-01,  3.96082832e-02,  1.69063798e-01,\n",
       "        2.53239024e-01, -1.70184146e-01,  2.13078739e-01, -1.89117961e-01,\n",
       "        2.22167885e-01, -1.50837536e-01,  8.91081990e-02, -1.96380013e-01,\n",
       "        6.60035035e-02,  1.01083809e-01,  2.91653106e-01,  8.18515451e-02,\n",
       "       -1.72381327e-01, -1.15072930e-01,  6.51718794e-02, -8.56596011e-03,\n",
       "       -2.62989499e-01, -2.17080791e-01,  9.49964211e-02,  1.50262654e-01,\n",
       "        1.90351662e-01,  1.46195325e-01,  4.80057192e-02,  1.36161151e-01,\n",
       "       -1.71236411e-01, -2.97211409e-01, -2.55384405e-01,  1.67400122e-01,\n",
       "       -2.38149580e-01, -1.21063440e-01, -3.04106647e-01, -5.75325405e-02,\n",
       "       -4.97627540e-02,  6.11827424e-03,  1.80084841e-01, -1.85431110e-01,\n",
       "        1.72095359e-01, -9.33525615e-02,  1.78297253e-02, -2.14109369e-01,\n",
       "        1.66776565e-01,  1.88443796e-01, -2.62986791e-01, -1.89394312e-01,\n",
       "        1.91648312e-01,  3.23819328e-01,  1.64454548e-01, -1.25795567e-01,\n",
       "       -1.36536952e-01,  1.60160238e-01, -3.05043265e-01, -2.72563857e-01,\n",
       "        1.40185163e-01,  7.02291911e-02,  3.97875260e-01,  1.95130599e-01,\n",
       "       -1.46832807e-01,  2.99703514e-01, -5.92353236e-02, -2.00606479e-02,\n",
       "       -2.01370287e-01,  7.95447366e-02,  1.78258538e-01,  2.09016083e-01,\n",
       "        9.09570407e-02, -3.49518638e-01,  3.49400953e-02, -1.38590432e-01,\n",
       "       -1.87196204e-01,  4.42458361e-02,  5.30835092e-02,  6.18931210e-02])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_methods = [method_name for method_name in dir(glove)]\n",
    "glove.word_vectors[glove.dictionary['only']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence2vector(data, glove):\n",
    "    x = []\n",
    "    for line in data:\n",
    "        vector = []\n",
    "        for word in line:\n",
    "            if word in glove.dictionary.keys():\n",
    "                vector.append(glove.word_vectors[glove.dictionary[word]])\n",
    "        x.append(vector)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: 15076\n",
      "X_test 3770\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test = sentence2vector(X_train, model), sentence2vector(X_test, model)\n",
    "print('X_train: %d\\nX_test %d' % (len(X_train), len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def averageVectors(data, labels):\n",
    "    avg = []\n",
    "    labels_clear = []\n",
    "    for row, label in zip(data, labels):\n",
    "        if len(row) > 0:\n",
    "            sample = sum(row)/len(row)\n",
    "            avg.append(sample)\n",
    "            labels_clear.append(label)\n",
    "    return avg, labels_clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = averageVectors(X_train, y_train)\n",
    "X_test, y_test = averageVectors(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "if T_SNE:\n",
    "    tsne = TSNE(verbose=1, n_iter=2500, learning_rate=1000)\n",
    "    result = tsne.fit_transform(X_train)\n",
    "    \n",
    "    import random\n",
    " \n",
    "    def colors(n):\n",
    "        ret = []\n",
    "        r = int(random.random() * 256)\n",
    "        g = int(random.random() * 256)\n",
    "        b = int(random.random() * 256)\n",
    "        step = 256 / n\n",
    "        for i in range(n):\n",
    "            r += step\n",
    "            g += step\n",
    "            b += step\n",
    "            r = int(r) % 256\n",
    "            g = int(g) % 256\n",
    "            b = int(b) % 256\n",
    "            ret.append((r/256,g/256,b/256)) \n",
    "        return ret\n",
    "\n",
    "    colors = colors(20)\n",
    "    m = plt.get_cmap()\n",
    "    x = np.array(np.matrix(result)[:,0].reshape(1,-1))\n",
    "    y = np.array(np.matrix(result)[:,1].reshape(1,-1))\n",
    "    c = [colors[i] for i in y_train]\n",
    "    plt.scatter(x, y, c=c)\n",
    "    plt.savefig('glove.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: 15076\n",
      "X_test 3770\n",
      "\n",
      "Example:\n",
      "[ 0.19665052  0.13148975  0.11489718  0.06313163  0.11216958 -0.09665706\n",
      "  0.03054124  0.02772437 -0.1936699   0.08954351 -0.03490513 -0.05817913\n",
      "  0.04941081 -0.05879615  0.00299012 -0.03500903 -0.08708629 -0.10821586\n",
      " -0.02003703  0.05965656 -0.10798991 -0.15392292  0.03046072 -0.00411286\n",
      " -0.04510488  0.11960951 -0.00507757  0.04310217  0.0495707   0.09407486\n",
      " -0.0197391   0.10784171 -0.08249628  0.03185181  0.03938374 -0.02412637\n",
      " -0.0559407  -0.01030827  0.10387594 -0.03923275  0.03887461 -0.03878042\n",
      "  0.03773385 -0.05610722 -0.06940983  0.03639879  0.15632733 -0.08056015\n",
      " -0.07349539  0.01332725 -0.0639918  -0.14213716 -0.14900329  0.12765242\n",
      " -0.07522953  0.10097406  0.07609285 -0.02244475 -0.10117409  0.0490825\n",
      " -0.01133064  0.11982951  0.10635011  0.09593495  0.17497404 -0.11105407\n",
      "  0.01850728 -0.10221129  0.0645162   0.05840711  0.06400835 -0.030579\n",
      " -0.04097324  0.17057143  0.03826791  0.03836644  0.01143341 -0.06120741\n",
      " -0.03280361  0.09351289  0.05387498  0.06993492 -0.01110792 -0.01214201\n",
      "  0.05368408  0.06587606  0.08190734  0.01999671 -0.02869014 -0.10083044\n",
      " -0.06072588 -0.03548704 -0.07062333  0.07335751  0.06335104  0.0478033\n",
      " -0.07307771  0.18401098 -0.01542419  0.03482983  0.10349214 -0.04976569\n",
      "  0.09458778  0.05157338 -0.15574773 -0.02910039  0.00149377  0.10340842\n",
      "  0.0266975   0.03275491  0.0660498  -0.13799207  0.02269418 -0.108319\n",
      "  0.10366438  0.05324421 -0.01018543 -0.00902943  0.14165511  0.02985897\n",
      " -0.09489982 -0.07047425  0.14028623  0.11657141  0.08993358 -0.05449373\n",
      " -0.05023961 -0.04447398  0.09944448 -0.1759154  -0.07543668  0.09751833\n",
      "  0.0534416   0.02229923 -0.06277397 -0.11402237 -0.08396138  0.02118205\n",
      " -0.12266989 -0.09490798 -0.08584116  0.05887847 -0.05367261 -0.09652856\n",
      " -0.1068011   0.03371474 -0.14186719  0.0794325   0.11176653  0.11905176\n",
      "  0.03695073 -0.05305847 -0.05052908 -0.02673463  0.05627015  0.08948016\n",
      "  0.05073555 -0.03276298  0.01779333  0.07310009  0.06732246  0.08356153\n",
      " -0.09305515  0.1584423  -0.03684706  0.13697106 -0.07375512  0.15965446\n",
      "  0.08648816  0.02202217 -0.0289052  -0.16355396 -0.11650396 -0.17316646\n",
      "  0.07550588  0.12827865 -0.04706567 -0.0734512  -0.07508091 -0.07075884\n",
      "  0.02990992 -0.06536382  0.10715527  0.03821968  0.0300541  -0.08814451\n",
      "  0.02089325 -0.02892785 -0.00846595 -0.09136344  0.10090279  0.09799951\n",
      " -0.01855681  0.0928409   0.02000017 -0.04895998 -0.00664775 -0.09944375\n",
      "  0.03648834 -0.08485676 -0.1007996   0.0398854  -0.07189808 -0.08910482\n",
      "  0.01977819 -0.04740351 -0.03313412  0.05720959  0.04111111 -0.11103315\n",
      " -0.08530118 -0.02946273  0.0612152   0.05789246 -0.05056397 -0.15653716\n",
      " -0.20973087 -0.0445624   0.01921435  0.16463948  0.01707359  0.01173313\n",
      " -0.07868796 -0.04598892  0.03152935 -0.04412766 -0.01084309  0.05112937\n",
      "  0.13936037 -0.17217764  0.11450876 -0.1047127  -0.02769441 -0.11863675\n",
      "  0.11050987 -0.08229891  0.01307026  0.12144832  0.04050708  0.0821129\n",
      " -0.03692298 -0.12755404 -0.05496408 -0.05643396 -0.07311285  0.02560318\n",
      " -0.04055612  0.09092297  0.15607471  0.14792741  0.01478643  0.01485293\n",
      " -0.05587287 -0.1184128  -0.12243235  0.12693229 -0.05029305 -0.05849745\n",
      " -0.10943345 -0.03873963 -0.11191531 -0.06671207  0.09644101 -0.06200505\n",
      "  0.14388068  0.03267268  0.03460519 -0.06878868  0.17323601  0.14781001\n",
      " -0.00666752 -0.10604245  0.08487364  0.07893723  0.10662303 -0.12602803\n",
      "  0.03984759  0.1168775  -0.08895667 -0.0409084   0.04092742 -0.02086232\n",
      "  0.04732335  0.0803876  -0.12711194  0.07971117  0.05758372  0.03065216\n",
      " -0.13001776  0.04243588  0.08766763  0.12372519  0.12153565 -0.01849964\n",
      " -0.05293591 -0.1060631  -0.0884565   0.04384923  0.0049093  -0.08909973]\n"
     ]
    }
   ],
   "source": [
    "print('X_train: %d\\nX_test %d' % (len(X_train), len(X_test)))\n",
    "print('\\nExample:')\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO randomowe slowa, wybrac najbardziej podobne uzyc tsne i narysowac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda: 1.000000 acc: 0.618 \n",
      "Lambda: 0.100000 acc: 0.675 \n",
      "Lambda: 0.010000 acc: 0.707 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ns/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda: 0.001000 acc: 0.725 \n",
      "Lambda: 0.000100 acc: 0.719 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ns/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "for reg in [1, 10, 100, 1000, 10000]:\n",
    "    classifier = LogisticRegression(\n",
    "                solver='lbfgs', max_iter=3000, multi_class='multinomial', C=reg)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    print(\"Lambda: %f acc: %.3f \" % (1/reg, classifier.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
