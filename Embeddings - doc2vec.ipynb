{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_COUNT = 5 # the minimal number of occurences for a particular word in order to be included\n",
    "SIZE = 100 # the size of the embedding\n",
    "TEST_SET = 0.2\n",
    "T_SNE = False\n",
    "K_MEANS = True\n",
    "CLASSIFIER = True\n",
    "DM = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = fetch_20newsgroups(subset='all', shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(line):\n",
    "    line = re.sub('[!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n]', ' ', line)\n",
    "    line = re.sub('[0-9]', '', line)\n",
    "    words = line.lower().split()\n",
    "    proper = []\n",
    "    for word in words:\n",
    "        if len(word) > 2:\n",
    "            proper.append(word)\n",
    "    return proper\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset.data, dataset.target, test_size=TEST_SET)\n",
    "X_train, X_test = [preproc(line) for line in X_train], [preproc(line) for line in X_test]\n",
    "X_train = [TaggedDocument(doc, [i]) for i, doc in enumerate(X_train)]\n",
    "X_test = [TaggedDocument(doc, [i]) for i, doc in enumerate(X_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec(size=SIZE, dm=DM, min_count=5)\n",
    "model.build_vocab(X_train)\n",
    "model.train(X_train, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [model.docvecs[i] for i in range(len(X_train))]\n",
    "X_test = [model.infer_vector(X_test[i][0]) for i in range(len(X_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for reg in [1, 10, 100, 1000, 10000]:\n",
    "    classifier = LogisticRegression(\n",
    "                solver='lbfgs', max_iter=3000, multi_class='multinomial', C=reg)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    print(\"Lambda: %f acc: %.3f \" % (1/reg, classifier.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances, silhouette_score\n",
    "\n",
    "scores = []\n",
    "for k in range(2, 25):\n",
    "    model = KMeans(n_clusters=k).fit(X_train)\n",
    "    labels = model.labels_\n",
    "    score = silhouette_score(X_train, labels, metric='euclidean')\n",
    "    scores.append(score)\n",
    "    print('K = %d\\tScore = %f' % (k, score))\n",
    "\n",
    "plt.plot(np.arange(2, 25), scores)\n",
    "plt.savefig('kmeans-doc2vec-DM.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = X_train + X_test\n",
    "y_all = np.concatenate([y_train, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(verbose=1, n_iter=250)\n",
    "result = tsne.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "def colors(n):\n",
    "    ret = []\n",
    "    r = int(random.random() * 256)\n",
    "    g = int(random.random() * 256)\n",
    "    b = int(random.random() * 256)\n",
    "    step = 256 / n\n",
    "    for i in range(n):\n",
    "        r += step\n",
    "        g += step\n",
    "        b += step\n",
    "        r = int(r) % 256\n",
    "        g = int(g) % 256\n",
    "        b = int(b) % 256\n",
    "        ret.append((r/256,g/256,b/256)) \n",
    "    return ret\n",
    "colors = colors(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m = plt.get_cmap()\n",
    "x = np.array(np.matrix(result)[:,0].reshape(1,-1))\n",
    "y = np.array(np.matrix(result)[:,1].reshape(1,-1))\n",
    "c = [colors[i] for i in y_train]\n",
    "plt.scatter(x, y, c=c)\n",
    "plt.savefig('doc2ec-non-def.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
